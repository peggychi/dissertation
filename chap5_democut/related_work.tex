%!TEX root = ../thesis.tex
\section{Related Work}
%MD: removing intro for now to save on space. Can bring it back if we have the space.

%Relevant prior research covers studies of purpose and use of online tutorials; systems that help users capture, annotate and edit video; novel techniques for consuming instructional content; and tools for creating tutorials for software. We discuss each area in turn.

%\bh{refs that fell by the wayside: Spyn \cite{Rosner:2010wv}, Maneesh's assembly instructions, Kuznetsov, IKEA. I'm fine without those refs.}

\subsection{Current Practices around How-To Videos}
%md: again removing for space - can come back if we one of you really wants this part

%People increasingly integrate information technology into physical leisure activities such as handwork and crafts~\cite{Goodman:2011fp}. Creating and using How-To videos is one particular outlet of this trend. The availability of still and video cameras in mobile phones has led to an explosion of user-generated content that is uploaded to the Web without any postproduction~\cite{Muller:2009tw}.
The research community has been investigating the motivations of both authors and viewers of how-to videos and written tutorials. While one primary motivation is to share expertise, published videos also serve as a way to broadcast skill and as an online portfolio~\cite{Torrey:2007he}. Authors may derive revenue through advertising or referrals~\cite{Lafreniere:2012tl}. Viewers, on the other hand, typically seek technical explanations, but are also searching for inspiration~\cite{Torrey:2009fc} and looking for validation of existing skills~\cite{Lafreniere:2012tl}.
In aggregate, these studies suggest that how-to videos have a larger variety of purposes and uses than merely communicating technical content.
%of these types of videos implies that technical clarity, while important, is not necessarily the only goal of video tutorials.
In our work we strive to make authoring of how-to videos more accessible to amateurs while maintaining opportunities for adding individual style through control over editing effects.

%\bh{This section is vague - I'm not sue what I learn from it. I didn't edit this much as I didn't have time to understand this set of papers yet.}
%Studies have shown that users capture video of physical activities for various purposes including archiving and  sharing\cite{Brown:2000jv}. Video and audio diaries are more effective to capture and recall a workflow than text \cite{Eldridge:1993va,Carter:2005tr}.
%Torrey et al. interviewed online tutorial makers to understand their knowledge sharing behaviors, which include project building, documentation, and broadcast to communities for knowledge exchange \cite{Torrey:2007he}. Lafreniere et al. analyzed community comments of web tutorials and suggested that authors share experiences not only for teaching but also to validate their skills \cite{Lafreniere:2012tl}. Kuznetsov and Paulos derived design implications from their large-scale survey across several DIY communities, including the challenges of new media formats and bridging physical and digital domains \cite{Kuznetsov:2010ve}. Rosner and Bean also pointed out the need of creative tools from their study with online IKEA hackers \cite{Rosner:2009uu}.
% Pipek: Knowledge Sharing in Maintenance Engineering \cite{Pipek:2003wq}; social network \cite{Ploderer:2010gq}
%
%Researchers are exploring the opportunities of designing digital technology to support physical tasks. Goodman et al. proposed three roles that digital tools may play based on their field study of handwork: extending (engagement with information), interjecting (use of external tools), and segmenting (for activities in space and time) \cite{Goodman:2011fp}. Spyn is a mobile phone application that records information such as audio, visual media, text, and locations during the knitting process \cite{Rosner:2010wv}. In addition, there are several commercial projects that support novice users creating tutorials using mobile devices, such as Snapguide\footnote{http://snapguide.com/} that provides step-by-step multimedia templates and Vine\footnote{http://vine.co/} for short video instructions.
% StoryCrate: live film production \cite{Bartindale:2012ck}

\subsection{Video Capture, Annotation and Editing}
\subsubTitleBold{Capture} Several research and commercial systems guide users at capture time to yield higher-quality videos. Such systems often employ templates to help users capture sequences of distinct shots (e.g., Snapguide\footnote{http://snapguide.com/}) or suggest framing of the subject or camera view as in NudgeCam~\cite{Carter:2010}. Computer vision algorithms, like face tracking, can be used to offer real-time feedback during such directed actions~\cite{Davis:2003cu,Heer:2004ba,Carter:2010}. Instead of relying on templates, shot suggestions can also be bootstrapped through user dialogs~\cite{Adams:2005}. In contrast to these systems, we work with a single long video take and do not require the author to manipulate the camera during capture. Many leisure activities, such as home repair or cooking, require use of both hands or involve getting one's hands dirty, so camera manipulation is not possible.

\subsubTitleBold{Annotation} Researchers have investigated how to provide interactions that enable efficient, fluid annotation of video data, from the early EVA system~\cite{Mackay:1989} to more recent interfaces like VideoTater that leverage pen input~\cite{Diakopoulos:2006vt}. We do not claim a contribution in the interaction techniques of our annotation interface and take inspiration from such prior work.

\subsubTitleBold{Editing} Frame-based editing of video is very time-intensive, as it forces users to operate at a very low level of detail. Editors can leverage metadata, such as transcripts~\cite{Berthouzoz:2012} and shot boundaries~\cite{Casares:2002dx}, to give users higher-level editing operations at the shot level rather than the frame level.
%In specific video domains like interview videos, transcripts can help users place cuts and transitions~\cite{Berthouzoz:2012}.
Computer vision techniques can automate certain effects, such as creating cinemagraphs~\cite{Bai:2012, Joshi:2012}, automatically-edited lecture videos~\cite{Heck:2007}, zoomable tapestries~\cite{Barnes:2010} and synopses~\cite{Pritch:2009vl}, or stabilizing shaky amateur videos~\cite{Liu:2011}. When analyzing video is a matter of subjective taste, identifying salient frames can also be outsourced to crowd workers~\cite{Bernstein:2011uj}. DemoCut also uses vision techniques for automatic editing. It differs from previous approaches in its focus on a particular application domain -- physical demonstration videos. By focusing on a specific domain, DemoCut can make assumptions about the structure of the input and output video, such as the fact that there is a linear set of steps, and offer an interface and algorithms that make it easier to create high quality how-to videos.

\subsection{Creating Effective Tutorials}
There are many ways to produce effective tutorials. One approach is to track user behavior to automate tutorial authoring~\cite{Grabler:2009jj, Grossman:2010jz, Chi:2012fq}. This method also opens the door to interactive tutorials that can respond to user progress~\cite{Bergman:2005:DocWizards, Pongnumkul:2011ju}. However, tracking user behavior in the physical world, rather than in software, remains a challenge.  DuploTrack uses a depth camera to track progress and provide guidance for block assembly tasks~\cite{Gupta:2012ku}.
 %Lovell and Buechley use electrical sensing with conductive thread for a sewing tutorial~\cite{Lovell:2010tl}.
%md: there is nothing interactive about the Lovell work. I am not sure it's a good fit in this section
Augmented reality applications overlay real-time information on top of the work area, usually through a head-mounted display. Such systems can provide visual highlights (such as arrows, text, closeup views, and 3D models) for machine maintenance \cite{Henderson:2011ff}, or interactive remote tutoring for repair tasks~\cite{Gurevich:2012ko}.

In this work we seek to support a wide variety of how-to tasks from craft to home repair and cooking where automatically tracking user activities is not yet possible. To support these tasks we propose a semi-automatic approach where the user marks important moments and the system automatically edits the video based on the user markers. Here we focus on the authoring of how-to videos, and we leave interactive tutorials for physical tasks to future work.

%md: incorporated software stuff above - don't think we need it here
%\subsection{Systems for Authoring and Navigating Software Tutorials}
%In recent years, considerable work has addressed automating the creation and navigation of tutorials for complex software applications. Examples include generating step-by-step instructions from demonstrations\cite{Grabler:2009jj,Chi:2012fq}, and capturing and reviewing workflow histories~\cite{Grossman:2010jz}. Pause-and-Play extracts commands used in an online video to help users follow the video step-by-step~\cite{Pongnumkul:2011ju}. These systems generally rely on application instrumentation to know which actions a user is performing. Different from this research domain, we focus on video recording of a broad range of physical demonstrations, where such information is not easily available. We therefore use a mixed-initiative approach that elicits additional annotations from the video authors. \md{what about including DocWizards? Could lump it with Pause and Play on interactive playback mechanisms?}


%In addition to effective procedural instruction design for physical tasks such as assembling \cite{Agrawala:2003fx}, one thriving research area is building augmented reality (AR) applications that project real-time information based on the work context. Henderson and Feiner developed a system that provides visual highlights (such as arrows, text, closeup views, and 3D models) via a head-worn display for machine maintenance tasks \cite{Henderson:2011ff}. Other research work includes interactive remote tutoring \cite{Gurevich:2012ko}, collaboration via head-mounted display \cite{Fussell:2003te}, document tracking and navigation \cite{Kim:2004fu}, and storytelling \cite{Barnes:2008tz}.
%\bh{not sure if AR systems and assembly instructions belong in the same paragaph.}
% Their system also allowed users to navigate the instruction sequences via a wearable display; cooking video segmentation [Miura et al. 03]

%We are also aware of research that automatically produces and analyzes videos. Clustered synopsis is a new video summarization approach that identifies similar motion in a video and presents the flow in a frame \cite{Pritch:2009vl}. Using computer vision and audition, Active Capture automatically directs actors with real-time feedback based on their performance, such as to scream louder or slowly turn to face the camera \cite{Davis:2003cu,Heer:2004ba}. Researchers also showed different video editing techniques using metadata \cite{Casares:2002eq,Casares:2002dx} and crowdsourcing \cite{Bernstein:2011uj}. \bh{This is so brief that when reading it I had no idea the last ref was for Adrenaline. Probably needs to be expanded.}
% [NAME OF STARTUP] develops techniques that identify key moments in the video and enhance with visual highlights.

%Our goal is to understand the available techniques from these domains in order to develop a mixed-initiative system that assists users in generating and editing instructional videos.

%\subsection{Current Practices of Creating How-To Instructions}
%\bh{Overall this subsection could probably be condensed a bit}
%We survey the motivations and current practices how people create DIY tutorials. Studies have shown that users capture physical activities using media devices for various purposes including archiving and distributing \cite{Brown:2000jv}, and video and audio diaries were more effective to capture and recall a workflow than text \cite{Eldridge:1993va,Carter:2005tr}. Torrey et al. interviewed online tutorial makers to understand their knowledge sharing behaviors, which include project building, documentation, and broadcast to communities for knowledge exchange \cite{Torrey:2007he}. Lafreniere et al. analyzed community comments of web tutorials and suggested that authors share experiences not only for teaching but also to validate their skills \cite{Lafreniere:2012tl}. Kuznetsov and Paulos derived design implications from their large-scale survey across several DIY communities, including the challenges of new media formats and bridging physical and digital domains \cite{Kuznetsov:2010ve}. Rosner and Bean also pointed out the need of creative tools from their study with online IKEA hackers \cite{Rosner:2009uu}.
% Pipek: Knowledge Sharing in Maintenance Engineering \cite{Pipek:2003wq}; social network \cite{Ploderer:2010gq}

%Researchers are exploring the opportunities of designing digital technology to support physical tasks. Goodman et al. proposed three roles that digital tools may play based on their field study of handwork: extending (engagement with information), interjecting (use of external tools), and segmenting (for activities in space and time) \cite{Goodman:2011fp}. Spyn is a mobile phone application that records information such as audio, visual media, text, and locations during the knitting process \cite{Rosner:2010wv}. In addition, there are several commercial projects that support novice users creating tutorials using mobile devices, such as Snapguide\footnote{http://snapguide.com/} that provides step-by-step multimedia templates and Vine\footnote{http://vine.co/} for short video instructions.
% StoryCrate: live film production \cite{Bartindale:2012ck}

%We look for opportunities to bring digital technologies in the How-To video creation process, to fulfill hobbyists' interests in sharing with minimum editing efforts by having them focus on their demonstrations.
