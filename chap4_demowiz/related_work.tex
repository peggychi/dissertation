%!TEX root = ../thesis.tex
\section{Related Work}

% \subsection{Workflow Capturing and Tutorials}
% There has been a considerable amount of research and many commercial tools devoted to revealing input events and operation sequences for software applications. Researchers have shown that visualizing input events in real-time during operations can provide better learnability of applications \cite{Dixon:2010fb}. Tools such as Mouseposé\footnote{Mouseposé http://www.boinx.com/mousepose} and ScreenFlow\footnote{ScreenFlow http://www.telestream.net/screenflow} capture mouse and keyboard events and apply special effects, such as drawing a circle around a mouse cursor. Workflows can also be captured from existing screencast videos \cite{Banovic:2012kd} and screenshots \cite{Yeh:2009dh}. In addition to visually enhancing events, presenting operation history helps users review the workflow. Approaches include annotating screenshot images with markers and arrows \cite{Grabler:2009jj,Nakamura:2008:ASV:1449715.1449721}, showing a list of before and after thumbnails and video clips \cite{Grossman:2010jz}, and creating a union graph of operations for workflow comparison \cite{Kong:2012:DTR:2207676.2208549}. These projects demonstrate the benefits of recognizing and visualizing events. Our work is related in that we use the stream of input events, but is focused on enhancing \textit{a speaker's} experience in a live presentation by visualizing events \textit{in advance} of the happening moments.

% Another closely related area is the design of various tutorial formats that help viewers operate an interactive system. Work includes embedding video snippets in application tooltips \cite{Grossman:2010wr}, mixed-media tutorials that combine operation-based video segments with text descriptions and screenshots \cite{Chi:2012:MAG:2380116.2380130}, and application-in-tutorial design enhanced by community-shared workflows \cite{Lafreniere:2013ff}. These designs show possible ways for viewers to explore application features interactively, but again, differ from our goal of real-time assistance for presenters.

% \subsection{Visualizing and Navigating Video Content}
% Videos can be navigated at the content level beyond log events, such as visualizing subject movements in a storyboard design \cite{goldman2006schematic} and enabling direct manipulation of a target in 2D \cite{Dragicevic:2008:VBD:1357054.1357096,Goldman:2008:VOA:1449715.1449719,Karrer:2008:DDM:1357054.1357097} or 3D \cite{Nguyen:2013:DMV:2470654.2466150}. These techniques help viewers understand content flow and playback videos, and have been applied to screencast videos \cite{Denoue:2013:RDM:2451176.2451190}. It is also possible to automate video control based on user actions for scenarios such as operating software applications \cite{Pongnumkul:2011ju} and block assembling tasks \cite{Gupta:2012ku}. Such novel forms of video navigation inspired us to explore new visual designs for revealing the video content that support live presentations.

\subsection{Presentation Tools}
Modern presentation tools have supported embedding video recordings and animation. Recent research has proposed advanced designs for content creation and navigation beyond simple slideshow composition, including: tools that help presenters compose content in a large canvas \cite{Good:2002:ZUI:941231.941236} as a path \cite{Lichtschlag:2009:FTA:1518701.1518786} or a directed graph \cite{Spicer:2012:NAD:2379790.2379795} derived from zoomable graphical interfaces \cite{Bederson:1994:PZG:192426.192435}; structure slides using markup languages \cite{Edge:2013:HDP:2470654.2470749} or sketching \cite{Li:2003:SIP:958432.958476}; and define animation programmatically \cite{Zongker:2003:CAP:846276.846319}. There has also been work on analyzing slide content for search and reuse \cite{Bergman:2010:OWP:1719970.1719999,Sharmin:2012:SCC:2166966.2166992} and comparing revisions in a design process \cite{Drucker:2006:CMM:1166253.1166263}. Our work shares similar goals of structuring a presentation based on event inputs that can be navigated and edited. However, we focus more on presentation enhancements of video content specifically for software demonstrations rather than on the authoring experience of the presentation itself.

Research on presenting information that can be perceived at a glance \cite{Matthews:2006:DEG:1142405.1142457} helps presenters recall the content during a presentation, such as a callout to show finer resolution of an overall view \cite{Baudisch:2002:KTC:503376.503423}. Closely related, Time Aura provides ambient cues of a pile of slides using colors and a timeline for pacing \cite{Mamykina:2001:TAI:365024.365077}. Recent research shows that people like to have better control of the presentation even though it requires more effort \cite{Lee:2013:STM:2553699.2553755}, and earlier studies suggest that designing an integrated presentation tool for complicated tasks could be challenging \cite{Johnson:1996:CPS:226159.226161}. These findings inspired our design on revealing content of a demo video with information that can be perceived with minimum attention.
