%!TEX root = ../thesis.tex
\section{Related Work}

Previous HCI research on instructional content falls into four main categories: 1) new tutorial formats and interfaces [1,6,9,12,14,15,18]; 2) automated methods for generating tutorials [3,8,10,18]; 3) studies evaluating the effectiveness of different instructional formats [8,9,11,16,17]; and 4) techniques for searching and analyzing collections of tutorials [5,13]. Our work on generating and evaluating mixed-media tutorials addresses the first three of these topics. In this section, we describe related work on new tutorials formats and automatic generation of instructional content. The following section discusses previous studies on tutorial effectiveness in the context of our own formative study.

New forms of instructional content: While static step-by-step and video tutorials are the most prevalent forms of instructional content, researchers have been exploring new formats and interfaces for learning materials. Many efforts propose instructional aids that work in conjunction with the target application, including in-application step-by-step wizards [1,12,6] and Q\&A forums [15], video-based tooltips [9], interactive video tutorials [18], command recommenders [14], and interface facades for mapping commands between applications [19]. Some systems also include features that facilitate navigation within tutorials, such as annotated video timelines [10,18] and reactive “current step” indicators [6]. Our work introduces an interactive mixed-media tutorial format that combines aspects of both step-by-step and video-based learning aids. \

Automatic generation of learning materials: One of our key contributions is a method for automatically generating mixed-media tutorials from user demonstrations. Most existing tutorial generation approaches analyze traces of user interactions through the application or screencast video of the demonstration. Methods that analyze user action traces [8,3,10] often capture application-level semantics about specific tools and their purpose, while techniques that analyze screen recordings [18,20,4] use computer vision to identify GUI interactions such as clicking on an icon or button. In MixT, we combine and extend these approaches to create step-by-step tutorials that incorporate text, images, and several formats of video.
